---
categories:  
- ""    #the front matter should be like the one found in, e.g., blog2.md. It cannot be like the normal Rmd we used
- ""
date: "2021-10-19"
description: The first excercise we did to learn R # the title that will show up once someone gets to this page
draft: false
image: R_pic.jpg # save picture in \static\img\blogs. Acceptable formats= jpg, jpeg, or png . Your iPhone pics wont work

keywords: ""
slug: beginnings_R # slug is the shorthand URL address... no spaces plz
title: Learning to use R
---

  

```{r, setup, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

# default figure size
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center"
)
```


```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(fivethirtyeight)
library(here)
library(skimr)
library(janitor)
library(vroom)
library(tidyquant)
library(ggrepel)
library(rvest) # to scrape wikipedia page
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(vroom)
library(tidyquant)
library(rvest)    # scrape websites
library(purrr)  
library(lubridate) #to handle dates
library(ggrepel)
```



# Where Do People Drink The Most Beer, Wine And Spirits?


Here we uploaded our first dataset. Thanks to Professor Kostis, the first dataset was about alchool and spirits, so it was an enjoyable first dataset to look at!



```{r, load_alcohol_data}
library(fivethirtyeight)
data(drinks)
```


One of the first simple tasks that was given to us was to use the glimpse function. This allowed us to look at the dataset's variables in a more comprehensive way. 


```{r glimpse_skim_data}
glimpse(drinks)
levels(drinks$beer_servings)
```

Here we made our first graph. In this graph we showed the 25 countries where the most consumption of beer takes place. In this graph we explored some features of ggplot and managed to order countries from top (highest beer consumption) to bottom (lowest beer consumption among the highest 25). 

```{r beer_plot}
drinks %>%
  slice_max(order_by = beer_servings, n=25) %>% 
  ggplot(aes(x=beer_servings, y=reorder(country, beer_servings)))+
  geom_col(colour="black", fill="gold")+
  labs(
    title="25 highest beer servings countries",
    x="Beer Servings",
    y="Country"
  )
  NULL

```

Here we did the same, but with Wine!

```{r wine_plot}

# YOUR CODE GOES HERE
drinks %>%
  slice_max(order_by = wine_servings, n=25) %>% 
  ggplot(aes(x=wine_servings, y=reorder(country, wine_servings)))+
  geom_col(colour="black",fill="red" )+
  labs(
    title="25 highest wine servings countries",
    x="Wine Servings",
    y="Country"
  )
  NULL


```


From these graphs we can notice that, first of all, countries the drink most beer tend to not be the ones that drink the most wine. Also, I was honestly not expecting a country like Namibia to be at the top of the most beer_servings countries in the world. But as our professor wisely says: "Don't let you bias into the data!"




# Challenge 2: Opinion polls for the 2021 German elections

After hours spent crying on R's errors and blaming whoever played a part inventing the computer, we finally arrived to our last excercise of our first homework: Challenge 2! Here we were supposed to download data about the opinion polling for the 2021 German federal election and reproduce a graph similar ro the one produced by the Guardian in the following article: :https://www.theguardian.com/world/2021/aug/20/german-election-poll-tracker-who-will-be-the-next-chancellor



```{r, scrape_wikipedia_polling_data, warnings= FALSE, message=FALSE}
url <- "https://en.wikipedia.org/wiki/Opinion_polling_for_the_2021_German_federal_election"

# similar graphs and analyses can be found at 
# https://www.theguardian.com/world/2021/jun/21/german-election-poll-tracker-who-will-be-the-next-chancellor
# https://www.economist.com/graphic-detail/who-will-succeed-angela-merkel


# get tables that exist on wikipedia page 
tables <- url %>% 
  read_html() %>% 
  html_nodes(css="table")


# parse HTML tables into a dataframe called polls 
# Use purr::map() to create a list of all tables in URL
polls <- map(tables, . %>% 
             html_table(fill=TRUE)%>% 
             janitor::clean_names())


# list of opinion polls
german_election_polls <- polls[[1]] %>% # the first table on the page contains the list of all opinions polls
  slice(2:(n()-1)) %>%  # drop the first row, as it contains again the variable names and last row that contains 2017 results
  mutate(
         # polls are shown to run from-to, e.g. 9-13 Aug 2021. We keep the last date, 13 Aug here, as the poll date
         # and we extract it by picking the last 11 characters from that field
         end_date = str_sub(fieldwork_date, -11),
         
         # end_date is still a string, so we convert it into a date object using lubridate::dmy()
         end_date = dmy(end_date),
         
         # we also get the month and week number from the date, if we want to do analysis by month- week, etc.
         month = month(end_date),
         week = isoweek(end_date)
         )
```


```{r}
head(german_election_polls)

poll<- as.data.frame(german_election_polls)
poll <- poll[complete.cases(poll), ]
clean_data <- poll %>% select(-c(1,2,3,4,11,12,13,15,16)) 
  
library(reshape2) #cardinal sin against dplyr
mdf <- melt(clean_data,id.vars="end_date")

col<-c("union"="black","spd"="red","af_d"="blue","grune"="green","linke"="purple","fdp"="yellow")

ggplot(mdf, aes(x = end_date, y = value, color = variable, group = variable)) + 
  geom_point(alpha = 0.5) +
  geom_ma(ma_fun  = SMA, n = 10, linetype = "solid") +
  scale_color_manual(values=col) +
  #scale_linetype_manual(values=c("union"="solid",
   #                              "spd"="solid",
    #                             "af_d"="solid",
     #                            "grune"="solid",
      #                           "linke"="solid",
       #                          "fdp"="solid"))+
  scale_fill_manual(values=col, aes(alpha=1)) 
 #fix legend, axes (scale and  ticks), fix colours


```


# Deliverables

There is a lot of explanatory text, comments, etc. You do not need these, so delete them and produce a stand-alone document that you could share with someone. Knit the edited and completed R Markdown file as an HTML document (use the "Knit" button at the top of the script editor window) and upload it to Canvas.

# Details

- Who did you collaborate with: TYPE NAMES HERE
- Approximately how much time did you spend on this problem set: ANSWER HERE
- What, if anything, gave you the most trouble: ANSWER HERE


**Please seek out help when you need it,** and remember the [15-minute rule](https://mfa2022.netlify.app/syllabus/#the-15-minute-rule){target=_blank}. You know enough R (and have enough examples of code from class and your readings) to be able to do this. If you get stuck, ask for help from others, post a question on Slack-- and remember that I am here to help too!  

> As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else? 

ofc

# Rubric

Check minus (1/5): Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. 

Check (3/5): Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). 

Check plus (5/5): Finished all components of the assignment correctly and addressed both challenges. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output.









